{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from lib.read_data import dataset,Datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# feature extractors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# finetuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cadd_annotation(file_path):\n",
    "    '''\n",
    "    load original cadd annotation\n",
    "    '''\n",
    "    dtype = {'#Chrom':np.object,\n",
    "            'isDerived':np.object,\n",
    "            'motifEName':np.object,\n",
    "            'motifEHIPos':np.object,\n",
    "            'PolyPhenCat':np.object,\n",
    "            'SIFTcat':np.object}\n",
    "    cadd_anno = pd.read_csv(file_path,sep='\\t',dtype=dtype)\n",
    "    print('Cadd annotation loaded.')\n",
    "    return cadd_anno\n",
    "def read_data_set(data_table,test_size=0.25,BENCHMARK=False):\n",
    "    '''\n",
    "    convert a pandas dataframe data table into Datasets(dataset,dataset)\n",
    "    '''\n",
    "    train, test = train_test_split(data_table,test_size=0.25)\n",
    "    train_x = train[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]]\n",
    "    features = train_x.columns\n",
    "    train_x = np.array(train_x)\n",
    "    test_x = np.array(test[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]])\n",
    "    train_y = np.array(train['INFO'],dtype=np.int8)\n",
    "    test_y = np.array(test['INFO'],dtype=np.int8)\n",
    "\n",
    "    if BENCHMARK:\n",
    "        return Datasets(train=dataset(train_x,train_y,features),\n",
    "                        test=dataset(test_x,test_y,features)),\\\n",
    "                        train['gavin_res'],\\\n",
    "                        test['gavin_res']\n",
    "    return Datasets(train=dataset(train_x,train_y,features),\n",
    "                    test=dataset(test_x,test_y,features))\n",
    "\n",
    "def run_display_output(classifier,test,DRAW=False):\n",
    "    '''\n",
    "    get confusion matrix and auc score for test dataset\n",
    "    (optional) draw roc curve\n",
    "    '''\n",
    "    pred = classifier.predict(test.values)\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    tn, fp, fn, tp = confusion_matrix(test.labels,pred).ravel()#confusion matrix\n",
    "    print(tn,fp,fn,tp)\n",
    "    sensitivity = tp/(fn+tp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    prods = classifier.predict(test.values)\n",
    "    if hasattr(classifier,'predict_proba'):\n",
    "        prods = classifier.predict_proba(test.values)[:,1]\n",
    "    else:\n",
    "        probs = classifier.predict(test.values)\n",
    "    fpr, tpr, _ = metrics.roc_curve(test.labels, prods)\n",
    "    score = metrics.auc(fpr,tpr) #auc score\n",
    "    if DRAW:\n",
    "        draw_roc_curve(fpr,tpr,score)\n",
    "\n",
    "    return sensitivity, specificity, score\n",
    "\n",
    "def display_res_gavin_and_best_model(param_grid,pipeline,mvid,filename=None):\n",
    "    '''\n",
    "    use model defined by pipeline to fit mvid Dataset\n",
    "    gridsearchCV determine the parameters given in param_grid\n",
    "    (optional) save the model in path given in filename\n",
    "    '''\n",
    "    classifier = GridSearchCV(estimator=pipeline,\n",
    "                              param_grid=param_grid)\n",
    "\n",
    "    print('Start training...')\n",
    "    classifier.fit(mvid.train.values,mvid.train.labels)\n",
    "    print('Model Description:\\n',classifier.best_estimator_)\n",
    "    if filename:\n",
    "        pickle.dump(classifier,open(filename,'wb'))\n",
    "        print('Saved model to path:',filename)\n",
    "    sensitivity,specificity,score = run_display_output(classifier,mvid.test)\n",
    "    print('>>> best model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "    return classifier\n",
    "\n",
    "def inference(classifier,dataset):\n",
    "    sensitivity,specificity,score = run_display_output(classifier,dataset.test)\n",
    "    print('>>> transfer to myo5b gene: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "\n",
    "def read_gavin(gavin_res, labels):\n",
    "    '''\n",
    "    compare gavin results with labels for a certain subset of data\n",
    "    '''\n",
    "    gavin_res = gavin_res.replace('Pathogenic',1)\n",
    "    gavin_res = gavin_res.replace('Benign',0)\n",
    "    tn_g, fp_g, fn_g, tp_g = \\\n",
    "    confusion_matrix(labels, gavin_res.astype(np.int8)).ravel()\n",
    "    sensitivity_g = tp_g/(fn_g+tp_g)\n",
    "    specificity_g = tn_g/(fp_g+tn_g)\n",
    "    return sensitivity_g, specificity_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadd annotation loaded.\n",
      "Drop features that I do not know how to impute.\n",
      "42 priPhCons\n",
      "11208 bStatistic\n",
      "70 mutIndex\n",
      "320266 mirSVR-Score\n",
      "320266 mirSVR-E\n",
      "320266 mirSVR-Aln\n",
      "350487 targetScan\n",
      "11390 fitCons\n",
      "758 EncH3K27Ac\n",
      "1013 EncH3K4Me1\n",
      "585 EncH3K4Me3\n",
      "2830 EncNucleo\n",
      "349579 motifECount\n",
      "349579 motifEScoreChng\n",
      "68483 cDNApos\n",
      "68483 relcDNApos\n",
      "72796 CDSpos\n",
      "72796 relCDSpos\n",
      "72796 protPos\n",
      "72796 relProtPos\n",
      "259931 Dst2Splice\n",
      "162523 Grantham\n",
      "Make dummy variables. Now the data has shape: (350503, 17122)\n",
      "Added the INFO column.\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    file_path = os.path.join('data','all_variants','cadd_with_info_no_nan_all_imputed.tsv')\n",
    "    all_variants = load_cadd_annotation(file_path)\n",
    "\n",
    "    all_variants['INFO'] = all_variants['INFO'].astype('category')\n",
    "    all_variants['INFO'] = all_variants['INFO'].cat.codes\n",
    "\n",
    "    print('Drop features that I do not know how to impute.')\n",
    "    for col in all_variants.select_dtypes(exclude=[np.object]).columns:\n",
    "        null = all_variants[col].isnull().values.sum()\n",
    "        if null>0:\n",
    "            all_variants = all_variants.drop([col],axis=1)\n",
    "            print(null, col)\n",
    "        \n",
    "    dummy_all_var=all_variants.drop(['Anc','INFO','chr_pos'],axis=1)\n",
    "    dummy_all_var = pd.get_dummies(dummy_all_var,sparse=True)\n",
    "    print('Make dummy variables. Now the data has shape:',dummy_all_var.shape)\n",
    "\n",
    "    dummy_all_var['INFO'] = all_variants['INFO']\n",
    "    print('Added the INFO column.')\n",
    "\n",
    "\n",
    "    # read data\n",
    "#     processed_all = pd.read_csv('data/myh7/myh7_myo5b.csv',sep='\\t')\n",
    "#     processed_myh7 = processed_all.loc[processed_all['genename']=='MYH7']\n",
    "#     processed_myo5b = processed_all.loc[processed_all['genename']=='MYO5B']\n",
    "#     processed_myo5b = processed_myo5b.drop('genename',axis=1) # drop pos\n",
    "#     processed_myh7 = processed_myh7.drop('genename',axis=1) # drop pos\n",
    "    \n",
    "#     myh7_data = read_data_set(processed_myh7,BENCHMARK=False)\n",
    "#     myo5b_data = read_data_set(processed_myo5b,BENCHMARK=False)\n",
    "    full_data = read_data_set(dummy_all_var,BENCHMARK=False)\n",
    "    print('Dataset loaded.',full_data.train.values.shape)\n",
    "\n",
    "# # ================model selection==========================================\n",
    "#     # # PCA + LogisticRegression\n",
    "#     # # Parameters\n",
    "#     n_components = np.arange(10,50,10)\n",
    "#     class_weight = ['balanced']#,{1:2,0:1}]\n",
    "#     param_grid_logr = [{'pca__n_components':n_components,\n",
    "#                    'logr__penalty':['l1'],#'l2'],\n",
    "#                    'logr__C':[2],#3,4,5],\n",
    "#                    'logr__class_weight':class_weight}]\n",
    "#     # pipeline\n",
    "#     pipeline_logr = Pipeline(steps=[('pca',PCA()),\n",
    "#                                ('logr',LogisticRegression())])\n",
    "#     # save model\n",
    "#     filename = os.path.join('model')#,'pca_logr_new.sav')\n",
    "#     # display results\n",
    "#     classifier_logr = display_res_gavin_and_best_model(param_grid_logr,\n",
    "#                                      pipeline_logr,\n",
    "#                                      myh7_data)#,\n",
    "#                                      #filename)\n",
    "    \n",
    "#     inference(classifier_logr,myo5b_data)\n",
    "#     # display gavin results\n",
    "#     sensitivity_g,specificity_g = read_gavin(test_gavin,myh7_data.test.labels)\n",
    "#     print('>>> gavin model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}'.\\\n",
    "#     format(sensitivity_g,specificity_g,prec=3))\n",
    "\n",
    "# ==========================================================\n",
    "#     # Linear model + SGDregressor\n",
    "#     # Parameters\n",
    "#     n_components = np.arange(10,50,10)\n",
    "#     loss = ['squared_loss', 'huber',\n",
    "#             'epsilon_insensitive', \n",
    "#             'squared_epsilon_insensitive']\n",
    "#     penalty = ['l1','l2','elasticnet']\n",
    "#     l1_ratio = [0.15,0.2,0.5,0.8]\n",
    "#     learning_rate = ['constant','optimal','invscaling']\n",
    "#     param_grid_sgd = [{#'pca__n_components':n_components,\n",
    "#                    'sgd__penalty':penalty,\n",
    "#                    'sgd__loss':loss,\n",
    "#                    'sgd__l1_ratio':l1_ratio,\n",
    "#                    'sgd__learning_rate':learning_rate,\n",
    "#                    'sgd__tol':[1e-6],\n",
    "#                    'sgd__warm_start':[True],\n",
    "#                    'sgd__max_iter':[10000],\n",
    "#                    'sgd__eta0':[0.1,0.01,0.5],\n",
    "#                    'sgd__class_weight':['balanced']}]\n",
    "#     # pipeline\n",
    "#     pipeline_sgd = Pipeline(steps=[#('pca',PCA()),\n",
    "#                                ('sgd',SGDClassifier())])\n",
    "#     # save model\n",
    "#     filename = os.path.join('model','pca_logr_new.sav')\n",
    "#     # display results\n",
    "#     classifier_sgd = display_res_gavin_and_best_model(param_grid_sgd,\n",
    "#                                      pipeline_sgd,\n",
    "#                                      full_data)#,\n",
    "#                                      #filename)\n",
    "#     inference(classifier_sgd,full_data)\n",
    "    # ==========================================================\n",
    "    # Linear model + SGDregressor\n",
    "    # Parameters\n",
    "#     n_components = np.arange(10,50,10)\n",
    "    loss = ['squared_loss']#, 'huber',\n",
    "#             'epsilon_insensitive', \n",
    "#             'squared_epsilon_insensitive']\n",
    "    penalty = ['elasticnet']\n",
    "    l1_ratio = [0.15]#,0.2,0.5,0.8]\n",
    "    learning_rate = ['constant']#,'optimal','invscaling']\n",
    "    param_grid_sgd = [{#'pca__n_components':n_components,\n",
    "                   'sgd__penalty':penalty,\n",
    "                   'sgd__loss':loss,\n",
    "                   'sgd__l1_ratio':l1_ratio,\n",
    "                   'sgd__learning_rate':learning_rate,\n",
    "                   'sgd__tol':[1e-6],\n",
    "                   'sgd__warm_start':[True],\n",
    "                   'sgd__max_iter':[10000],\n",
    "                   'sgd__eta0':[0.1],#0.01,0.5],\n",
    "                   'sgd__class_weight':['balanced']}]\n",
    "    # pipeline\n",
    "    pipeline_sgd = Pipeline(steps=[#('pca',PCA()),\n",
    "                               ('sgd',SGDClassifier())])\n",
    "    # save model\n",
    "    filename = os.path.join('model','pca_logr_new.sav')\n",
    "    # display results\n",
    "    classifier_sgd = display_res_gavin_and_best_model(param_grid_sgd,\n",
    "                                     pipeline_sgd,\n",
    "                                     full_data)#,\n",
    "                                     #filename)\n",
    "    inference(classifier_sgd,full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

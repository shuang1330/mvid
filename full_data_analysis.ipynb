{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from lib.read_data import dataset,Datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# feature extractors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# finetuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cadd_annotation(file_path):\n",
    "    '''\n",
    "    load original cadd annotation\n",
    "    '''\n",
    "    dtype = {'#Chrom':np.object,\n",
    "            'isDerived':np.object,\n",
    "            'motifEName':np.object,\n",
    "            'motifEHIPos':np.object,\n",
    "            'PolyPhenCat':np.object,\n",
    "            'SIFTcat':np.object}\n",
    "    cadd_anno = pd.read_csv(file_path,sep='\\t',dtype=dtype)\n",
    "    print('Cadd annotation loaded.')\n",
    "    return cadd_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadd annotation loaded.\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join('data','all_variants','cadd_with_info_no_nan_all_imputed.tsv')\n",
    "all_variants = load_cadd_annotation(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ref</th>\n",
       "      <th>Anc</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Type</th>\n",
       "      <th>Length</th>\n",
       "      <th>isTv</th>\n",
       "      <th>Consequence</th>\n",
       "      <th>GC</th>\n",
       "      <th>CpG</th>\n",
       "      <th>priPhCons</th>\n",
       "      <th>...</th>\n",
       "      <th>PolyPhenCat</th>\n",
       "      <th>PolyPhenVal</th>\n",
       "      <th>SIFTcat</th>\n",
       "      <th>SIFTval</th>\n",
       "      <th>RawScore</th>\n",
       "      <th>PHRED</th>\n",
       "      <th>chr_pos</th>\n",
       "      <th>INFO</th>\n",
       "      <th>key</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NON_SYNONYMOUS</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.106787</td>\n",
       "      <td>11.25</td>\n",
       "      <td>1_1167659</td>\n",
       "      <td>PATHOGENIC</td>\n",
       "      <td>B3GALT6</td>\n",
       "      <td>1167659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NON_SYNONYMOUS</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.482313</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1_1167674</td>\n",
       "      <td>PATHOGENIC</td>\n",
       "      <td>B3GALT6</td>\n",
       "      <td>1167674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGGC</td>\n",
       "      <td>TGGC</td>\n",
       "      <td>T</td>\n",
       "      <td>DEL</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFRAME</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.924056</td>\n",
       "      <td>15.74</td>\n",
       "      <td>1_1167680</td>\n",
       "      <td>POPULATION</td>\n",
       "      <td>B3GALT6</td>\n",
       "      <td>1167680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGGC</td>\n",
       "      <td>TGGC</td>\n",
       "      <td>T</td>\n",
       "      <td>DEL</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPSTREAM</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.924056</td>\n",
       "      <td>15.74</td>\n",
       "      <td>1_1167680</td>\n",
       "      <td>POPULATION</td>\n",
       "      <td>SDF4</td>\n",
       "      <td>1167680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGGC</td>\n",
       "      <td>TGGC</td>\n",
       "      <td>T</td>\n",
       "      <td>DEL</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULATORY</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.065</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.924056</td>\n",
       "      <td>15.74</td>\n",
       "      <td>1_1167680</td>\n",
       "      <td>POPULATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1167680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ref   Anc Alt Type  Length   isTv     Consequence    GC   CpG  priPhCons  \\\n",
       "0     A     A   G  SNV       0  False  NON_SYNONYMOUS  0.85  0.40      0.022   \n",
       "1     C     C   T  SNV       0  False  NON_SYNONYMOUS  0.83  0.36      0.007   \n",
       "2  TGGC  TGGC   T  DEL       3    NaN         INFRAME  0.83  0.38      0.065   \n",
       "3  TGGC  TGGC   T  DEL       3    NaN        UPSTREAM  0.83  0.38      0.065   \n",
       "4  TGGC  TGGC   T  DEL       3    NaN      REGULATORY  0.83  0.38      0.065   \n",
       "\n",
       "    ...     PolyPhenCat  PolyPhenVal      SIFTcat  SIFTval  RawScore  PHRED  \\\n",
       "0   ...             NaN          0.0  deleterious     0.00  1.106787  11.25   \n",
       "1   ...             NaN          0.0  deleterious     0.03  4.482313  24.20   \n",
       "2   ...             NaN          0.0          NaN     0.00  1.924056  15.74   \n",
       "3   ...             NaN          0.0          NaN     0.00  1.924056  15.74   \n",
       "4   ...             NaN          0.0          NaN     0.00  1.924056  15.74   \n",
       "\n",
       "     chr_pos        INFO      key      POS  \n",
       "0  1_1167659  PATHOGENIC  B3GALT6  1167659  \n",
       "1  1_1167674  PATHOGENIC  B3GALT6  1167674  \n",
       "2  1_1167680  POPULATION  B3GALT6  1167680  \n",
       "3  1_1167680  POPULATION     SDF4  1167680  \n",
       "4  1_1167680  POPULATION      NaN  1167680  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_variants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding for categorical data\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# categorical_features = [fea for fea in all_variants.select_dtypes(\n",
    "#     include=[np.object]).columns if fea not in ['Anc','INFO','chr_pos']]\n",
    "dummy_all_var=all_variants.drop(['Anc','INFO','chr_pos'],axis=1)\n",
    "dummy_all_var = pd.get_dummies(dummy_all_var,sparse=True)\n",
    "\n",
    "# for feature in categorical_features:\n",
    "# #     if len(copy_all_var[feature].unique()) >100:\n",
    "# #         print(feature,len(copy_all_var[feature].unique()))\n",
    "#     try:\n",
    "#         copy_all_var[feature] = le.fit_transform(copy_all_var[feature])\n",
    "#     except:\n",
    "#         copy_all_var[feature] = copy_all_var[feature].fillna('0')\n",
    "#         copy_all_var[feature] = le.fit_transform(copy_all_var[feature])\n",
    "    \n",
    "# # scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_data_set(data_table,test_size=0.25,BENCHMARK=False):\n",
    "    '''\n",
    "    convert a pandas dataframe data table into Datasets(dataset,dataset)\n",
    "    '''\n",
    "    train, test = train_test_split(data_table,test_size=0.25)\n",
    "    train_x = train[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]]\n",
    "    features = train_x.columns\n",
    "    train_x = np.array(train_x)\n",
    "    test_x = np.array(test[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]])\n",
    "    train_y = np.array(train['INFO'],dtype=np.int8)\n",
    "    test_y = np.array(test['INFO'],dtype=np.int8)\n",
    "\n",
    "    if BENCHMARK:\n",
    "        return Datasets(train=dataset(train_x,train_y,features),\n",
    "                        test=dataset(test_x,test_y,features)),\\\n",
    "                        train['gavin_res'],\\\n",
    "                        test['gavin_res']\n",
    "    return Datasets(train=dataset(train_x,train_y,features),\n",
    "                    test=dataset(test_x,test_y,features))\n",
    "\n",
    "def run_display_output(classifier,test,DRAW=False):\n",
    "    '''\n",
    "    get confusion matrix and auc score for test dataset\n",
    "    (optional) draw roc curve\n",
    "    '''\n",
    "    pred = classifier.predict(test.values)\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    tn, fp, fn, tp = confusion_matrix(test.labels,pred).ravel()#confusion matrix\n",
    "    print(tn,fp,fn,tp)\n",
    "    sensitivity = tp/(fn+tp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    prods = classifier.predict(test.values)\n",
    "    if hasattr(classifier,'predict_proba'):\n",
    "        prods = classifier.predict_proba(test.values)[:,1]\n",
    "    else:\n",
    "        probs = classifier.predict(test.values)\n",
    "    fpr, tpr, _ = metrics.roc_curve(test.labels, prods)\n",
    "    score = metrics.auc(fpr,tpr) #auc score\n",
    "    if DRAW:\n",
    "        draw_roc_curve(fpr,tpr,score)\n",
    "\n",
    "    return sensitivity, specificity, score\n",
    "\n",
    "def display_res_gavin_and_best_model(param_grid,pipeline,mvid,filename=None):\n",
    "    '''\n",
    "    use model defined by pipeline to fit mvid Dataset\n",
    "    gridsearchCV determine the parameters given in param_grid\n",
    "    (optional) save the model in path given in filename\n",
    "    '''\n",
    "    classifier = GridSearchCV(estimator=pipeline,\n",
    "                              param_grid=param_grid)\n",
    "\n",
    "    print('Start training...')\n",
    "    classifier.fit(mvid.train.values,mvid.train.labels)\n",
    "    print('Model Description:\\n',classifier.best_estimator_)\n",
    "    if filename:\n",
    "        pickle.dump(classifier,open(filename,'wb'))\n",
    "        print('Saved model to path:',filename)\n",
    "    sensitivity,specificity,score = run_display_output(classifier,mvid.test)\n",
    "    print('>>> best model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "    return classifier\n",
    "\n",
    "def inference(classifier,dataset):\n",
    "    sensitivity,specificity,score = run_display_output(classifier,dataset.test)\n",
    "    print('>>> transfer to myo5b gene: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "\n",
    "def read_gavin(gavin_res, labels):\n",
    "    '''\n",
    "    compare gavin results with labels for a certain subset of data\n",
    "    '''\n",
    "    gavin_res = gavin_res.replace('Pathogenic',1)\n",
    "    gavin_res = gavin_res.replace('Benign',0)\n",
    "    tn_g, fp_g, fn_g, tp_g = \\\n",
    "    confusion_matrix(labels, gavin_res.astype(np.int8)).ravel()\n",
    "    sensitivity_g = tp_g/(fn_g+tp_g)\n",
    "    specificity_g = tn_g/(fp_g+tn_g)\n",
    "    return sensitivity_g, specificity_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    # read data\n",
    "#     processed_all = pd.read_csv('data/myh7/myh7_myo5b.csv',sep='\\t')\n",
    "#     processed_myh7 = processed_all.loc[processed_all['genename']=='MYH7']\n",
    "#     processed_myo5b = processed_all.loc[processed_all['genename']=='MYO5B']\n",
    "#     processed_myo5b = processed_myo5b.drop('genename',axis=1) # drop pos\n",
    "#     processed_myh7 = processed_myh7.drop('genename',axis=1) # drop pos\n",
    "    \n",
    "#     myh7_data = read_data_set(processed_myh7,BENCHMARK=False)\n",
    "#     myo5b_data = read_data_set(processed_myo5b,BENCHMARK=False)\n",
    "    full_data = read_data_set(dummy_all_var,BENCHMARK=False)\n",
    "    print('Dataset loaded.',full_data.train.values.shape)\n",
    "\n",
    "# # ================model selection==========================================\n",
    "#     # # PCA + LogisticRegression\n",
    "#     # # Parameters\n",
    "#     n_components = np.arange(10,50,10)\n",
    "#     class_weight = ['balanced']#,{1:2,0:1}]\n",
    "#     param_grid_logr = [{'pca__n_components':n_components,\n",
    "#                    'logr__penalty':['l1'],#'l2'],\n",
    "#                    'logr__C':[2],#3,4,5],\n",
    "#                    'logr__class_weight':class_weight}]\n",
    "#     # pipeline\n",
    "#     pipeline_logr = Pipeline(steps=[('pca',PCA()),\n",
    "#                                ('logr',LogisticRegression())])\n",
    "#     # save model\n",
    "#     filename = os.path.join('model')#,'pca_logr_new.sav')\n",
    "#     # display results\n",
    "#     classifier_logr = display_res_gavin_and_best_model(param_grid_logr,\n",
    "#                                      pipeline_logr,\n",
    "#                                      myh7_data)#,\n",
    "#                                      #filename)\n",
    "    \n",
    "#     inference(classifier_logr,myo5b_data)\n",
    "#     # display gavin results\n",
    "#     sensitivity_g,specificity_g = read_gavin(test_gavin,myh7_data.test.labels)\n",
    "#     print('>>> gavin model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}'.\\\n",
    "#     format(sensitivity_g,specificity_g,prec=3))\n",
    "\n",
    "# ==========================================================\n",
    "#     # Linear model + SGDregressor\n",
    "#     # Parameters\n",
    "#     n_components = np.arange(10,50,10)\n",
    "#     loss = ['squared_loss', 'huber',\n",
    "#             'epsilon_insensitive', \n",
    "#             'squared_epsilon_insensitive']\n",
    "#     penalty = ['l1','l2','elasticnet']\n",
    "#     l1_ratio = [0.15,0.2,0.5,0.8]\n",
    "#     learning_rate = ['constant','optimal','invscaling']\n",
    "#     param_grid_sgd = [{#'pca__n_components':n_components,\n",
    "#                    'sgd__penalty':penalty,\n",
    "#                    'sgd__loss':loss,\n",
    "#                    'sgd__l1_ratio':l1_ratio,\n",
    "#                    'sgd__learning_rate':learning_rate,\n",
    "#                    'sgd__tol':[1e-6],\n",
    "#                    'sgd__warm_start':[True],\n",
    "#                    'sgd__max_iter':[10000],\n",
    "#                    'sgd__eta0':[0.1,0.01,0.5],\n",
    "#                    'sgd__class_weight':['balanced']}]\n",
    "#     # pipeline\n",
    "#     pipeline_sgd = Pipeline(steps=[#('pca',PCA()),\n",
    "#                                ('sgd',SGDClassifier())])\n",
    "#     # save model\n",
    "#     filename = os.path.join('model','pca_logr_new.sav')\n",
    "#     # display results\n",
    "#     classifier_sgd = display_res_gavin_and_best_model(param_grid_sgd,\n",
    "#                                      pipeline_sgd,\n",
    "#                                      full_data)#,\n",
    "#                                      #filename)\n",
    "#     inference(classifier_sgd,full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

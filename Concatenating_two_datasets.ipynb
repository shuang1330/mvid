{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(datatable_pd,GeneName=False,POS=False,SAVE=False):\n",
    "    datatable_pos = datatable_pd['POS']\n",
    "    genename = datatable_pd['GeneName'].values\n",
    "    # delete some columns that were not used in cadd paper\n",
    "    del_cols = ['CHROM','POS','isDerived','AnnoType','ConsScore',\n",
    "                'ConsDetail','mapAbility20bp','mapAbility35bp',\n",
    "                'scoreSegDup','isKnownVariant','ESP_AF','ESP_AFR',\n",
    "                'ESP_EUR','TG_AF','TG_ASN','TG_AMR','TG_AFR','TG_EUR',\n",
    "                'GeneID','FeatureID','CCDS','GeneName','Exon',\n",
    "                'Intron']\n",
    "    datatable_pd = datatable_pd.drop(columns=del_cols)\n",
    "\n",
    "    # delete columns without a single value\n",
    "    datatable_pd = datatable_pd.dropna(axis=1,how='all')\n",
    "\n",
    "    # fill in values recommended by cadd paper\n",
    "    values = {'GerpRS':0, 'GerpRSpval':1,'EncExp':0,'EncOCC':5,\n",
    "              'EncOCCombPVal':0,'EncOCDNasePVal':0,'EncOCFairePVal':0,\n",
    "              'EncOCpolIIPVal':0,'EncOCctcfPVal':0,'EncOCmycPVal':0,\n",
    "              'EncOCDNaseSig':0,'EncOCFaireSig':0,'EncOCpolIISig':0,\n",
    "              'EncOCctcfSig':0,'EncOCmycSig':0,'tOverlapMotifs':0,\n",
    "              'motifDist':0,'TFBS':0,'TFBSPeaksMax':0,'PolyPhenVal':0,\n",
    "              'SIFTval':0,'TFBSPeaks':0}\n",
    "    datatable_pd = datatable_pd.fillna(values)\n",
    "    \n",
    "    # transform objects to dummies\n",
    "    categorical_feature_names = \\\n",
    "    datatable_pd.select_dtypes(include=np.object).columns\n",
    "    categories={} # contains all the levels in those feature columns\n",
    "    for f in categorical_feature_names:\n",
    "        datatable_pd[f] = datatable_pd[f].astype('category')\n",
    "        categories[f] = datatable_pd[f].cat.categories\n",
    "\n",
    "    dummy_data = pd.get_dummies(datatable_pd,columns=[col for col in\n",
    "                                                      categorical_feature_names\n",
    "                                                      if col not in ['INFO']])\n",
    "    \n",
    "    # change info column into scalar column\n",
    "    dummy_data['INFO'] = datatable_pd['INFO'].astype('category').cat.codes\n",
    "    \n",
    "    # drop nan values -TODO\n",
    "    dummy_data_del_all_nan = dummy_data.copy()\n",
    "    print('Deleted columns that I do not know how to impute:')\n",
    "    for col in dummy_data.columns:\n",
    "        null = dummy_data[col].isnull().values.ravel().sum()\n",
    "        if null > 0:\n",
    "            print(null,col)\n",
    "            dummy_data_del_all_nan = dummy_data_del_all_nan.drop(columns=col)\n",
    "    \n",
    "    # normalized the numerical values before any processing afterwards\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    dummy_data_scaled = min_max_scaler.fit_transform(dummy_data_del_all_nan)\n",
    "    dummy_data_scaled = pd.DataFrame(dummy_data_scaled,\n",
    "                                     columns=dummy_data_del_all_nan.columns)\n",
    "    \n",
    "    \n",
    "    # save the preprocessed data as csv file\n",
    "#     print(dummy_data_scaled.shape)\n",
    "#     print(genename.shape)\n",
    "#     print(dummy_data_scaled.index)\n",
    "#     raise NotImplementedError\n",
    "    if GeneName:\n",
    "        dummy_data_scaled['key'] = genename\n",
    "    if POS:\n",
    "        dummy_data_scaled['POS'] = datatable_pos\n",
    "    if SAVE:\n",
    "        res_path = os.path.join('data','dummy_no_nan_data.csv')\n",
    "        dummy_data_scaled.to_csv(res_path,sep='\\t',index=False)\n",
    "        print('Saved to %s'%res_path)\n",
    "    \n",
    "    return dummy_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "myh7_path = 'data/myh7/mhy7.tsv'\n",
    "myo5b_path = 'data/myo5b/myo5b_variants_patho_benign_cadd1.3fullannot_v1.xlsx'\n",
    "myh7 = pd.read_csv(myh7_path,sep='\\t')\n",
    "myo5b_excel = pd.ExcelFile(myo5b_path)\n",
    "myo5b = myo5b_excel.parse(myo5b_excel.sheet_names[0])\n",
    "del myo5b_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>INFO</th>\n",
       "      <th>Type</th>\n",
       "      <th>Length</th>\n",
       "      <th>isTv</th>\n",
       "      <th>isDerived</th>\n",
       "      <th>...</th>\n",
       "      <th>Intron</th>\n",
       "      <th>oAA</th>\n",
       "      <th>nAA</th>\n",
       "      <th>Grantham</th>\n",
       "      <th>PolyPhenCat</th>\n",
       "      <th>PolyPhenVal</th>\n",
       "      <th>SIFTcat</th>\n",
       "      <th>SIFTval</th>\n",
       "      <th>RawScore</th>\n",
       "      <th>PHRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>47352774</td>\n",
       "      <td>MYO5B:c.5616-2A&gt;G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334537</td>\n",
       "      <td>6.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>47361716</td>\n",
       "      <td>MYO5B:c.5392C&gt;T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.849415</td>\n",
       "      <td>48.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>47361725</td>\n",
       "      <td>MYO5B:c.5383C&gt;T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.701726</td>\n",
       "      <td>52.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>47365526</td>\n",
       "      <td>MYO5B:c.4840C&gt;T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.577744</td>\n",
       "      <td>46.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>47365610</td>\n",
       "      <td>MYO5B:c.4755_4756dupT</td>\n",
       "      <td>C</td>\n",
       "      <td>CCA</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>INS</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.553096</td>\n",
       "      <td>35.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHROM       POS                     ID REF  ALT        INFO Type  Length  \\\n",
       "0     18  47352774      MYO5B:c.5616-2A>G   T    C  Pathogenic  SNV       0   \n",
       "1     18  47361716        MYO5B:c.5392C>T   G    A  Pathogenic  SNV       0   \n",
       "2     18  47361725        MYO5B:c.5383C>T   G    A  Pathogenic  SNV       0   \n",
       "3     18  47365526        MYO5B:c.4840C>T   G    A  Pathogenic  SNV       0   \n",
       "4     18  47365610  MYO5B:c.4755_4756dupT   C  CCA  Pathogenic  INS       2   \n",
       "\n",
       "    isTv  isDerived   ...   Intron  oAA  nAA Grantham  PolyPhenCat  \\\n",
       "0  False       True   ...      NaN  NaN  NaN      NaN          NaN   \n",
       "1  False       True   ...      NaN    Q    *      NaN          NaN   \n",
       "2  False       True   ...      NaN    R    *      NaN          NaN   \n",
       "3  False       True   ...      NaN    Q    *      NaN          NaN   \n",
       "4    NaN       True   ...      NaN  NaN  NaN      NaN          NaN   \n",
       "\n",
       "   PolyPhenVal  SIFTcat  SIFTval   RawScore   PHRED  \n",
       "0          NaN      NaN      NaN   0.334537   6.023  \n",
       "1          NaN      NaN      NaN  14.849415  48.000  \n",
       "2          NaN      NaN      NaN  15.701726  52.000  \n",
       "3          NaN      NaN      NaN  14.577744  46.000  \n",
       "4          NaN      NaN      NaN   9.553096  35.000  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myo5b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Chrom</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Anc</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Type</th>\n",
       "      <th>Length</th>\n",
       "      <th>isTv</th>\n",
       "      <th>isDerived</th>\n",
       "      <th>AnnoType</th>\n",
       "      <th>...</th>\n",
       "      <th>nAA</th>\n",
       "      <th>Grantham</th>\n",
       "      <th>PolyPhenCat</th>\n",
       "      <th>PolyPhenVal</th>\n",
       "      <th>SIFTcat</th>\n",
       "      <th>SIFTval</th>\n",
       "      <th>RawScore</th>\n",
       "      <th>PHRED</th>\n",
       "      <th>chr_pos</th>\n",
       "      <th>INFO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>23882063</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CodingTranscript</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.880579</td>\n",
       "      <td>15.47</td>\n",
       "      <td>14_23882063</td>\n",
       "      <td>POPULATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>23882064</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CodingTranscript</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.823769</td>\n",
       "      <td>15.13</td>\n",
       "      <td>14_23882064</td>\n",
       "      <td>PATHOGENIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>23882082</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Transcript</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.428258</td>\n",
       "      <td>24.20</td>\n",
       "      <td>14_23882082</td>\n",
       "      <td>POPULATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>23882975</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CodingTranscript</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>94.0</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.130</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.518627</td>\n",
       "      <td>23.10</td>\n",
       "      <td>14_23882975</td>\n",
       "      <td>POPULATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>23882976</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>SNV</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>CodingTranscript</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>159.0</td>\n",
       "      <td>possibly_damaging</td>\n",
       "      <td>0.572</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.615639</td>\n",
       "      <td>26.60</td>\n",
       "      <td>14_23882976</td>\n",
       "      <td>POPULATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   #Chrom       Pos Ref Anc Alt Type  Length   isTv  isDerived  \\\n",
       "0      14  23882063   C   C   T  SNV       0  False       True   \n",
       "1      14  23882064   T   T   C  SNV       0  False       True   \n",
       "2      14  23882082   T   T   C  SNV       0  False       True   \n",
       "3      14  23882975   C   C   T  SNV       0  False       True   \n",
       "4      14  23882976   C   C   A  SNV       0   True       True   \n",
       "\n",
       "           AnnoType     ...      nAA  Grantham        PolyPhenCat  \\\n",
       "0  CodingTranscript     ...        *       NaN                NaN   \n",
       "1  CodingTranscript     ...        W       NaN                NaN   \n",
       "2        Transcript     ...      NaN       NaN                NaN   \n",
       "3  CodingTranscript     ...        D      94.0             benign   \n",
       "4  CodingTranscript     ...        C     159.0  possibly_damaging   \n",
       "\n",
       "   PolyPhenVal      SIFTcat  SIFTval  RawScore  PHRED      chr_pos        INFO  \n",
       "0          NaN          NaN      NaN  1.880579  15.47  14_23882063  POPULATION  \n",
       "1          NaN          NaN      NaN  1.823769  15.13  14_23882064  PATHOGENIC  \n",
       "2          NaN          NaN      NaN  4.428258  24.20  14_23882082  POPULATION  \n",
       "3        0.130  deleterious     0.02  3.518627  23.10  14_23882975  POPULATION  \n",
       "4        0.572  deleterious     0.00  5.615639  26.60  14_23882976  POPULATION  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myh7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "myh7 = myh7.rename(index=str,columns={'#Chrom':'CHROM','Pos':'POS','Ref':'REF','Alt':'ALT'})\n",
    "myh7 = myh7.drop(['Anc','chr_pos'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "myo5b = myo5b.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "myh7.loc[myh7['INFO']=='POPULATION','INFO']='Benign'\n",
    "myh7.loc[myh7['INFO']=='PATHOGENIC','INFO']='Pathogenic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(myh7.columns).symmetric_difference(set(myo5b.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the myh7 and myo5b datasets\n",
    "myh7_myo5b = pd.concat([myh7,myo5b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALT                 object\n",
       "AnnoType            object\n",
       "CCDS                object\n",
       "CDSpos             float64\n",
       "CHROM                int64\n",
       "ConsDetail          object\n",
       "ConsScore            int64\n",
       "Consequence         object\n",
       "CpG                float64\n",
       "Domain              object\n",
       "Dst2SplType         object\n",
       "Dst2Splice         float64\n",
       "ESP_AF             float64\n",
       "ESP_AFR            float64\n",
       "ESP_EUR            float64\n",
       "EncExp             float64\n",
       "EncH3K27Ac         float64\n",
       "EncH3K4Me1         float64\n",
       "EncH3K4Me3         float64\n",
       "EncNucleo          float64\n",
       "EncOCC             float64\n",
       "EncOCCombPVal      float64\n",
       "EncOCDNasePVal     float64\n",
       "EncOCDNaseSig      float64\n",
       "EncOCFairePVal     float64\n",
       "EncOCFaireSig      float64\n",
       "EncOCctcfPVal      float64\n",
       "EncOCctcfSig       float64\n",
       "EncOCmycPVal       float64\n",
       "EncOCmycSig        float64\n",
       "                    ...   \n",
       "isKnownVariant        bool\n",
       "isTv                object\n",
       "mamPhCons          float64\n",
       "mamPhyloP          float64\n",
       "mapAbility20bp     float64\n",
       "mapAbility35bp     float64\n",
       "minDistTSE           int64\n",
       "minDistTSS           int64\n",
       "mirSVR-Aln         float64\n",
       "mirSVR-E           float64\n",
       "mirSVR-Score       float64\n",
       "motifDist          float64\n",
       "motifECount        float64\n",
       "motifEHIPos        float64\n",
       "motifEName         float64\n",
       "motifEScoreChng    float64\n",
       "mutIndex           float64\n",
       "nAA                 object\n",
       "oAA                 object\n",
       "priPhCons          float64\n",
       "priPhyloP          float64\n",
       "protPos            float64\n",
       "relCDSpos          float64\n",
       "relProtPos         float64\n",
       "relcDNApos         float64\n",
       "scoreSegDup        float64\n",
       "tOverlapMotifs     float64\n",
       "targetScan         float64\n",
       "verPhCons          float64\n",
       "verPhyloP          float64\n",
       "Length: 116, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myh7_myo5b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted columns that I do not know how to impute:\n",
      "74 CDSpos\n",
      "803 Dst2Splice\n",
      "3 EncH3K27Ac\n",
      "78 EncNucleo\n",
      "224 Grantham\n",
      "57 cDNApos\n",
      "1080 mirSVR-Aln\n",
      "1080 mirSVR-E\n",
      "1080 mirSVR-Score\n",
      "74 protPos\n",
      "74 relCDSpos\n",
      "74 relProtPos\n",
      "57 relcDNApos\n"
     ]
    }
   ],
   "source": [
    "processed_myh7_myo5b = preprocessing(myh7_myo5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CHROM', 'POS', 'Length', 'isDerived', 'ConsScore', 'GC', 'CpG',\n",
       "       'mapAbility20bp', 'mapAbility35bp', 'scoreSegDup', 'priPhCons',\n",
       "       'mamPhCons', 'verPhCons', 'priPhyloP', 'mamPhyloP', 'verPhyloP',\n",
       "       'GerpN', 'GerpS', 'GerpRS', 'GerpRSpval', 'bStatistic', 'mutIndex',\n",
       "       'dnaHelT', 'dnaMGW', 'dnaProT', 'dnaRoll', 'mirSVR-Score', 'mirSVR-E',\n",
       "       'mirSVR-Aln', 'targetScan', 'fitCons', 'cHmmTssA', 'cHmmTssAFlnk',\n",
       "       'cHmmTxFlnk', 'cHmmTx', 'cHmmTxWk', 'cHmmEnhG', 'cHmmEnh',\n",
       "       'cHmmZnfRpts', 'cHmmHet', 'cHmmTssBiv', 'cHmmBivFlnk', 'cHmmEnhBiv',\n",
       "       'cHmmReprPC', 'cHmmReprPCWk', 'cHmmQuies', 'EncExp', 'EncH3K27Ac',\n",
       "       'EncH3K4Me1', 'EncH3K4Me3', 'EncNucleo', 'EncOCC', 'EncOCCombPVal',\n",
       "       'EncOCDNasePVal', 'EncOCFairePVal', 'EncOCpolIIPVal', 'EncOCctcfPVal',\n",
       "       'EncOCmycPVal', 'EncOCDNaseSig', 'EncOCFaireSig', 'EncOCpolIISig',\n",
       "       'EncOCctcfSig', 'EncOCmycSig', 'tOverlapMotifs', 'motifDist',\n",
       "       'motifECount', 'motifEName', 'motifEHIPos', 'motifEScoreChng', 'TFBS',\n",
       "       'TFBSPeaks', 'TFBSPeaksMax', 'isKnownVariant', 'ESP_AF', 'ESP_AFR',\n",
       "       'ESP_EUR', 'TG_AF', 'TG_ASN', 'TG_AMR', 'TG_AFR', 'TG_EUR',\n",
       "       'minDistTSS', 'minDistTSE', 'cDNApos', 'relcDNApos', 'CDSpos',\n",
       "       'relCDSpos', 'protPos', 'relProtPos', 'Dst2Splice', 'Grantham',\n",
       "       'PolyPhenVal', 'SIFTval', 'RawScore', 'PHRED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myh7.select_dtypes(exclude=[np.object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add genename to processed table\n",
    "processed_myh7_myo5b['genename'] = myh7_myo5b['GeneName'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_myh7 = processed_myh7_myo5b.loc[processed_myh7_myo5b['genename']=='MYH7']\n",
    "processed_myo5b = processed_myh7_myo5b.loc[processed_myh7_myo5b['genename']=='MYO5B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_myo5b = processed_myo5b.drop('genename',axis=1) # drop pos\n",
    "processed_myh7 = processed_myh7.drop('genename',axis=1) # drop pos\n",
    "processed_myh7_myo5b.to_csv('data/myh7/myh7_myo5b.csv',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse, not relevant to this file, but I kept the results though.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.read_data import dataset,Datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# feature extractors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "# finetuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_set(data_table,test_size=0.25,BENCHMARK=False):\n",
    "    '''\n",
    "    convert a pandas dataframe data table into Datasets(dataset,dataset)\n",
    "    '''\n",
    "    train, test = train_test_split(data_table,test_size=0.25)\n",
    "    train_x = train[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]]\n",
    "    features = train_x.columns\n",
    "    train_x = np.array(train_x)\n",
    "    test_x = np.array(test[[col for col in train.columns\n",
    "    if col not in ['INFO','gavin_res']]])\n",
    "    train_y = np.array(train['INFO'],dtype=np.int8)\n",
    "    test_y = np.array(test['INFO'],dtype=np.int8)\n",
    "\n",
    "    # # check what columns are in the train Dataset\n",
    "    # for i in range(0,len(train_x.columns),5):\n",
    "    #     print(train_x.columns[i:i+5])\n",
    "\n",
    "    if BENCHMARK:\n",
    "        return Datasets(train=dataset(train_x,train_y,features),\n",
    "                        test=dataset(test_x,test_y,features)),\\\n",
    "                        train['gavin_res'],\\\n",
    "                        test['gavin_res']\n",
    "    return Datasets(train=dataset(train_x,train_y,features),\n",
    "                    test=dataset(test_x,test_y,features))\n",
    "\n",
    "def run_display_output(classifier,test,DRAW=False):\n",
    "    '''\n",
    "    get confusion matrix and auc score for test dataset\n",
    "    (optional) draw roc curve\n",
    "    '''\n",
    "    pred = classifier.predict(test.values)\n",
    "    tn, fp, fn, tp = confusion_matrix(test.labels,pred).ravel()#confusion matrix\n",
    "    print(tn,fp,fn,tp)\n",
    "    sensitivity = tp/(fn+tp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    prods = classifier.predict_proba(test.values)[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(test.labels, prods)\n",
    "    score = metrics.auc(fpr,tpr) #auc score\n",
    "    if DRAW:\n",
    "        draw_roc_curve(fpr,tpr,score)\n",
    "\n",
    "    return sensitivity, specificity, score\n",
    "\n",
    "def display_res_gavin_and_best_model(param_grid,pipeline,mvid,filename=None):\n",
    "    '''\n",
    "    use model defined by pipeline to fit mvid Dataset\n",
    "    gridsearchCV determine the parameters given in param_grid\n",
    "    (optional) save the model in path given in filename\n",
    "    '''\n",
    "    classifier = GridSearchCV(estimator=pipeline,\n",
    "                              param_grid=param_grid)\n",
    "\n",
    "    print('Start training...')\n",
    "    classifier.fit(mvid.train.values,mvid.train.labels)\n",
    "    print('Model Description:\\n',classifier.best_estimator_)\n",
    "    if filename:\n",
    "        pickle.dump(classifier,open(filename,'wb'))\n",
    "        print('Saved model to path:',filename)\n",
    "    sensitivity,specificity,score = run_display_output(classifier,mvid.test)\n",
    "    print('>>> best model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "    return classifier\n",
    "\n",
    "def inference(classifier,dataset):\n",
    "    sensitivity,specificity,score = run_display_output(classifier,dataset.test)\n",
    "    print('>>> best model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}\\tauc:{}'.\\\n",
    "    format(sensitivity,specificity,score,prec=3))\n",
    "\n",
    "def read_gavin(gavin_res, labels):\n",
    "    '''\n",
    "    compare gavin results with labels for a certain subset of data\n",
    "    '''\n",
    "    gavin_res = gavin_res.replace('Pathogenic',1)\n",
    "    gavin_res = gavin_res.replace('Benign',0)\n",
    "    tn_g, fp_g, fn_g, tp_g = \\\n",
    "    confusion_matrix(labels, gavin_res.astype(np.int8)).ravel()\n",
    "    sensitivity_g = tp_g/(fn_g+tp_g)\n",
    "    specificity_g = tn_g/(fp_g+tn_g)\n",
    "    return sensitivity_g, specificity_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. (637, 214)\n",
      "Start training...\n",
      "Model Description:\n",
      " Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logr', LogisticRegression(C=2, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "109 33 22 49\n",
      ">>> best model results: sensitivity: 0.69\tspecificity: 0.768\tauc:0.7723665939297759\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    # read data\n",
    "    myh7_data = read_data_set(processed_myh7,BENCHMARK=False)\n",
    "    myo5b_data = read_data_set(processed_myo5b,BENCHMARK=False)\n",
    "    # print(data.head())\n",
    "    # raise NotImplementedError # check the dataset loaded\n",
    "    print('Dataset loaded.',myh7_data.train.values.shape)\n",
    "\n",
    "# ================model selection==========================================\n",
    "    # # PCA + LogisticRegression\n",
    "    # # Parameters\n",
    "    n_components = np.arange(10,50,10)\n",
    "    class_weight = ['balanced']#,{1:2,0:1}]\n",
    "    param_grid_logr = [{'pca__n_components':n_components,\n",
    "                   'logr__penalty':['l1'],#'l2'],\n",
    "                   'logr__C':[2],#3,4,5],\n",
    "                   'logr__class_weight':class_weight}]\n",
    "    # pipeline\n",
    "    pipeline_logr = Pipeline(steps=[('pca',PCA()),\n",
    "                               ('logr',LogisticRegression())])\n",
    "    # save model\n",
    "    filename = os.path.join('model')#,'pca_logr_new.sav')\n",
    "    # display results\n",
    "    classifier_logr = display_res_gavin_and_best_model(param_grid_logr,\n",
    "                                     pipeline_logr,\n",
    "                                     myh7_data)#,\n",
    "                                     #filename)\n",
    "    \n",
    "#     # display gavin results\n",
    "#     sensitivity_g,specificity_g = read_gavin(test_gavin,myh7_data.test.labels)\n",
    "#     print('>>> gavin model results: sensitivity: {:.{prec}}\\tspecificity: {:.{prec}f}'.\\\n",
    "#     format(sensitivity_g,specificity_g,prec=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 31 2 10\n",
      ">>> best model results: sensitivity: 0.833\tspecificity: 0.380\tauc:0.705\n"
     ]
    }
   ],
   "source": [
    "inference(classifier_logr,myo5b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
